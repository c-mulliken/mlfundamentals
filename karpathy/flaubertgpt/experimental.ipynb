{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "import sys\n",
    "\n",
    "sys.path.append('/home/coby/Repositories/mlfundamentals/karpathy/flaubertgpt')\n",
    "\n",
    "from model import BigramLanguageModel\n",
    "from train import train, generate\n",
    "from data import load_dataset, train_test_split, get_vocab_size\n",
    "\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "# hyperparameters\n",
    "batch_size = 16\n",
    "block_size = 256\n",
    "max_iters = 4000\n",
    "eval_interval = 100\n",
    "lr = 3e-4\n",
    "eval_iters = 200\n",
    "n_embd = 384\n",
    "n_head = 6\n",
    "n_layer = 6\n",
    "dropout = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "text = load_dataset()\n",
    "train_data, test_data = train_test_split(text)\n",
    "train_data, test_data = train_data.to(device), test_data.to(device)\n",
    "vocab_size = get_vocab_size(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BigramLanguageModel(vocab_size, n_layer, n_head, n_embd, block_size, dropout, device).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 0, train loss : 4.9851, test loss : 4.9812\n",
      "step: 100, train loss : 2.4917, test loss : 2.4445\n",
      "step: 200, train loss : 2.4603, test loss : 2.4266\n",
      "step: 300, train loss : 2.4379, test loss : 2.4000\n",
      "step: 400, train loss : 2.4164, test loss : 2.3723\n",
      "step: 500, train loss : 2.3450, test loss : 2.3102\n",
      "step: 600, train loss : 2.2040, test loss : 2.1642\n",
      "step: 700, train loss : 2.0773, test loss : 2.0324\n",
      "step: 800, train loss : 2.0023, test loss : 1.9574\n",
      "step: 900, train loss : 1.9363, test loss : 1.8883\n",
      "step: 1000, train loss : 1.8684, test loss : 1.8231\n",
      "step: 1100, train loss : 1.8226, test loss : 1.7685\n",
      "step: 1200, train loss : 1.7746, test loss : 1.7284\n",
      "step: 1300, train loss : 1.7427, test loss : 1.6968\n",
      "step: 1400, train loss : 1.7064, test loss : 1.6581\n",
      "step: 1500, train loss : 1.6684, test loss : 1.6274\n",
      "step: 1600, train loss : 1.6414, test loss : 1.5967\n",
      "step: 1700, train loss : 1.6167, test loss : 1.5684\n",
      "step: 1800, train loss : 1.5931, test loss : 1.5370\n",
      "step: 1900, train loss : 1.5646, test loss : 1.5203\n",
      "step: 2000, train loss : 1.5395, test loss : 1.4950\n",
      "step: 2100, train loss : 1.5288, test loss : 1.4761\n",
      "step: 2200, train loss : 1.5068, test loss : 1.4515\n",
      "step: 2300, train loss : 1.4864, test loss : 1.4411\n",
      "step: 2400, train loss : 1.4718, test loss : 1.4344\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_iters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mblock_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_interval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_iters\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Repositories/mlfundamentals/karpathy/flaubertgpt/train.py:34\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, train_data, test_data, max_iters, lr, batch_size, block_size, eval_interval, eval_iters)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(max_iters):\n\u001b[1;32m     33\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m step \u001b[38;5;241m%\u001b[39m eval_interval \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m step \u001b[38;5;241m==\u001b[39m max_iters \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m---> 34\u001b[0m         losses \u001b[38;5;241m=\u001b[39m \u001b[43mestimate_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_iters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mblock_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     35\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstep: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstep\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, train loss : \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlosses[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, test loss : \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlosses[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     37\u001b[0m     xb, yb \u001b[38;5;241m=\u001b[39m get_batch(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m, train_data, test_data, batch_size, block_size)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/torch/utils/_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 116\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Repositories/mlfundamentals/karpathy/flaubertgpt/train.py:23\u001b[0m, in \u001b[0;36mestimate_loss\u001b[0;34m(model, eval_iters, train_data, test_data, batch_size, block_size)\u001b[0m\n\u001b[1;32m     21\u001b[0m         X, Y \u001b[38;5;241m=\u001b[39m get_batch(split, train_data, test_data, batch_size, block_size)\n\u001b[1;32m     22\u001b[0m         logits, loss \u001b[38;5;241m=\u001b[39m model(X, Y)\n\u001b[0;32m---> 23\u001b[0m         losses[k] \u001b[38;5;241m=\u001b[39m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     24\u001b[0m     out[split] \u001b[38;5;241m=\u001b[39m losses\u001b[38;5;241m.\u001b[39mmean()\n\u001b[1;32m     25\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train(model, train_data, test_data, max_iters, lr, batch_size, block_size, eval_interval, eval_iters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, 'models/model1.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "C4\n",
      "\n",
      "\n",
      "\n",
      "Bot have andied knowing with frien-roses, I speak you to are knows he manody,\n",
      "proving, she reCusises deced:\n",
      "\n",
      "“Taries doisor,” Emma celin away; then is a horses track away was terry\n",
      "with a cup trive of block while reaking and the lave.\n",
      "\n",
      "“Yer whatcher!” he said looking away her.\n",
      "\n",
      "And, he slowly not love one larked by the ivoary mans sarrawled manaththing; It\n",
      "is spook to her as to 5ges.”\n",
      "\n",
      "“Aranss all doctuo doing massers looking dare’s, “kyonde, I kill go on\n",
      "a neck culaveller,” she saided him, “The talls towe her, the harl with\n",
      "breen face, a twen darkned where standed, he serelf to king the terrains liked\n",
      "Normanous.”\n",
      "\n",
      "“Fruit up to delary’re coine mistself,—a is memple of it it up the\n",
      "conside one glinely were leading drapped on the new king black, where their\n",
      "her horses. It empty smoul of the paves---”\n",
      "\n",
      "“She thought towaked up.\n",
      "\n",
      "“Tanker,” roced speckosed between appidity.”\n",
      "\n",
      "As the most withering. The temple of latherness and palanumed around upose\n",
      "insienely her lavely. But herself t\n"
     ]
    }
   ],
   "source": [
    "chars = sorted(list(set(text)))\n",
    "vocab_size = len(chars)\n",
    "\n",
    "stoi = { ch : i for i, ch in enumerate(chars) }\n",
    "itos = { i : ch for i, ch in enumerate(chars) }\n",
    "\n",
    "encode = lambda s: [stoi[c] for c in s]\n",
    "decode = lambda l: ''.join([itos[i] for i in l])\n",
    "\n",
    "def generate(model, length, device, decode):\n",
    "    return decode(model.generate(idx = torch.zeros((1, 1), dtype=torch.long, device=device), max_new_tokens=length)[0].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "soldital, saw to him orright out his the copy the\n",
      "him.\n",
      "\n",
      "“Perhaps is! close!”\n",
      "\n",
      "“Yes for shout,” cried “ell,” said the apult.\n",
      "\n",
      "“You are trem back them, deavres solder, ask, so down them.”\n",
      "\n",
      "“I avou ge!”\n",
      "\n",
      "And last her no many yoursel light abbout up elbow her.\n",
      "Léoking she uptacks on their stones the insoluce shaill; creeks, when you were\n",
      "heart on displeted her sitting made dyiple must to the looke end\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "print(generate(model, 400, device, decode))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
